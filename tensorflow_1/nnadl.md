# 機械学習入門

前回TensorFlowのチュートリアルに沿って機械学習についての説明を始めましたが、説明をしてみて、TensorFlowのチュートリアルに沿って説明をするのではなく、機械学習の概念をちゃんと理解する方が順序として正しいと思い、機械学習入門を行います。  
主に機械学習とニューラルネットワーク等の機械学習周辺を話せればいいなと思っています。

## 今回の教材
[ニューラルネットワークと深層学習](http://nnadl-ja.github.io/nnadl_site_ja/index.html
)  
無料のオンライン書籍(の和訳のベータ版です。まだ和訳も途中のものです)。  
機械学習を学ぶといっているのに「深層学習」となっていますが、深層学習とは多層構造のニューラルネットワークの機械学習を意味します(機械学習の一種というイメージで大丈夫だと思います)。  
書籍に沿って進めるため(一部飛ばしたりするかもですが)、話が少しそれたりすることがあります。

## このテキストのゴール
**"機械学習をなんとなく理解する"**  
なぜなんとなくなのか？  
=> 単純に難しいからです。。  
※下記Qiita引用(引用元: [http://qiita.com/IshitaTakeshi/items/4607d9f729babd273960](http://qiita.com/IshitaTakeshi/items/4607d9f729babd273960))  
> 勉強会ではこんなことを聞きました。  
「アルゴリズムの実装もやりたいんだけど、その前に理論を理解したい」  
アルゴリズムを完璧に理解してからコードを書きたくなるというのはプログラマとしてすごくいい癖(素質)だと思います。  
しかし、機械学習に関しては、最初から完璧に理論を理解しようとするのはあまり良くないと私は思います。なぜなら、単純に難しいからです。  
機械学習の理論の大半は高度な数式で構成されています。  
最も単純なアルゴリズムであるパーセプトロンなら、高校レベルの数学力があれば容易に理解できます。しかし、それより少し性能のいいSVM(サポートベクターマシン)などを理解しようとすると、とたんに難しい部分がたくさん出てきます。  
例えば、SVMの最も重要な部分であるカーネル関数の原理を理解しようとすると、非常に高度な数学が必要になります。どのくらい高度か知りたい方は、「カーネル関数　原理」などでググってみて出てくる数式を眺めてみるといいでしょう。  
要は、「機械学習をやってみたい」もしくは「機械学習を始めてみた」という方がいきなり理論を完璧に理解するのはまず無理だということです。

## 入門を始める前に
入門のための入門をします。。  
先人がスライドを作成しているので、そちらを使用します。  
[http://www.slideshare.net/unnonouno/jubatus-casual-talks
](http://www.slideshare.net/unnonouno/jubatus-casual-talks
)

それでは、機械学習入門スタートします。

## ニューラルネットワークの歴史
プログラミングする従来の方法では、解きたい問題を、コンピュータに実行できるよう明確に定義された無数の小さなタスクに分割し、コンピュータに何をすべきか逐一指示します。  
これに対し、ニューラルネットワークを使う場合は、直接問題の解き方を指示しません。コンピュータが観測データから学習し、問題の解き方を自ら編み出します。  
ただし、2006年まではニューラルネットワークを訓練して、伝統的な手法より良い結果を出させる方法がわかっていませんでした。2006年に起きた変化が深層学習(ディープラーニング)の発見でした。そして手法が進歩した結果、音声認識や自然言語処理等における多くの重要な問題で、優れた実績を達成しています。

## ニューラルネットワークを用いた手書き文字認識
(TensorFlowで説明しようとしてたMNISTと同じか同等のものです)  
次の手書き数列を読んでみてください。  
<img src="http://nnadl-ja.github.io/nnadl_site_ja/images/digits.png" width=300px">  
(わりと簡単に?)**504192**と読めたでしょうか？  
では、このとき脳内ではどう処理されているでしょうか。脳で起こっていることは簡単どころではありません。  
脳の2つの半球にはそれぞれ、一次視覚野(V1とも呼ばれる)、1億4千万のニューロン(神経細胞)と何十億のシナプス(神経細胞間)からなる領域が存在します。さらに人間の視覚に関わっている領域は、V1,V2,V3,V4,V5という一連の視覚野が順次複雑な画像処理に携わっています。  
人は目に見えるものを解釈するという作業を得意とし、その作業を無意識のうちに行っています。  
これを手書き数字を認識するプログラムを書こうとすれば、視覚パターン認識の困難さが明らかになります。数字を認識するための直感的で単純なルール(数字の9は、上に輪があって、右下から下に向かって線が生えている形)をアルゴリズムで表現するのは決して単純ではありません。このようなルールを正確にプログラムで表現しようとすれば、すぐに膨大な例外、落とし穴、特殊ケースに気づくでしょう。  

ニューラルネットワークはこのような問題に違った角度から迫ります。ニューラルネットワークは下記のような手書き数字のデータをあらかじめたくさん用意して(このようなデータを訓練例や訓練データといいます)、その上で、訓練例から学習することのできるシステムを開発するというものです。  
言い換えると、訓練例をもとに、数字認識のルールを自動的に推論します。さらに訓練例を増やすと、ニューラルネットワークは手書き文字に関する知識をより多く獲得し、精度が向上します。
<img src="http://nnadl-ja.github.io/nnadl_site_ja/images/mnist_100_digits.png" width="500px">

手書き文字認識を理解する(書籍だと実装する)過程で、ニューラルネットワークの鍵となるアイデアをいくつか出てくるので、その中でも重要な人口ニューロン(パーセプトロンとシグモイドニューロン)や、ニューラルネットワークの標準的な学習アルゴリズムである確率的勾配降下法を紹介・なぜその手法なのかを説明していきます。(途中で挫折しなければですが。。。  )

### パーセプトロン
ニューラルネットワークとは何か、という解説を始めるにあたり、まずはパーセプトロンと呼ばれる種類の人口ニューロンから話を始めます。今日ではパーセプトロン以外の人口ニューロンモデルを扱うことが一般的です。現代のニューラルネットワーク研究の多くでは、シグモイドニューロンと呼ばれるモデルが主に使われていて、この後その説明もしますが、なぜシグモイドニューロンが今の姿をしているのかを知るために、こちらを理解することにします。

パーセプトロンとは何か?  
パーセプトロンは複数の2進数$$x_1, x_2, \ldots$$を入力にとり、ひとつの2進数を出力します。  

![パーセプトロンとは](http://nnadl-ja.github.io/nnadl_site_ja/images/tikz0.png)  

上図の例では、パーセプトロンは3つの入力$$x_1, x_2, x_3$$をとっています(一般的には入力はいくつでも構いません)。開発者は**重み**$$w_1, w_2, \ldots$$という概念を導入しました。  
重みとは、それぞれの入力が出力に及ぼす影響の大きさを表す実数です。パーセプトロンの出力が0になるか1になるかは、入力の重み付き和$$\sum_j w_j x_j$$と**閾値（しきい値）**の大小比較で決まります。重みと同じく、閾値もパーセプトロンの挙動を決める実数パラメータです。より正確に数式で表現するなら、  
$$\begin{eqnarray}
  \mbox{output} & = & \left\{ \begin{array}{ll}
      0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ threshold} \\
      1 & \mbox{if } \sum_j w_j x_j > \mbox{ threshold}
      \end{array} \right.
\tag{1}\end{eqnarray}$$  
パーセプトロンを動かすルールはこれだけです。  
直感的に言えば、パーセプトロンとは、複数の情報に重みをつけながら決定をくだす機械だといえます。

- 現実的な例  
週末に「チーズ祭り」が開催されます。あなたはチーズが好物で、チーズ祭りに行くかどうか決めようとしています。判断に影響を及ぼしそうなファクターは3つあります。

1. 天気はいいか
2. あなたの恋人も一緒に行きたがっているか？
3. 祭りの会場は駅から近いか？(電車を使用する前提)

これらの3つのファクターを2進数値$$x_1,x_2,x_3$$で表現し、天気が良いなら$$x_1=1$$、悪いなら$$x_1=0$$、同様に$$x_2,x_3$$を扱う。  
あなたはチーズが大好物で、恋人がなんと言おうが、会場が駅から遠かろうが、チーズ祭りに行くつもりかもしれません。一方、雨が何より苦手で、天気が悪かったら絶対に行くつもりはないかもしれません。パーセプトロンはこのような意思決定を表現することが可能です。  
1つの方法が天気の条件の重みを$$w_1=6$$、他の重みを$$w_2=2$$と$$w_3=2$$にすることです。重みの値が大きい条件はあなたの意思決定で大事なことであることを表します。最後に、パーセプトロンの閾値を5に設定します。以上のパラメータ設定により、パーセプトロンで意思決定モデルを実装できました。このパーセプトロンは天気が良ければ必ず1を出力し、天気が悪ければ0を出力します。恋人の意思や、駅からの距離によって結論が変わることはありません。  

重みと閾値を変化させることで様々な意思決定モデルを得ることが出来ます。たとえば、閾値を5から3に変えてみると、「天気が良い」**または**「会場が駅から近い **かつ** あなたの恋人が一緒に行きたがっている」となります。  
パーセプトロンは人間の意思決定モデルの完全なモデルではないですが、パーセプトロンはことなる種類の情報を考慮し、重みをつけた上で判断を下す能力が有るため、パーセプトロンを複雑に組み合わせたネットワークなら、かなり微妙な判断も扱えます。  

![パーセプトロン組み合わせ](http://nnadl-ja.github.io/nnadl_site_ja/images/tikz1.png)  

上図のネットワークでは、まず1列目の3つのパーセプトロン(第一層のパーセプトロンと呼ぶことにする)が入力情報に重みをつけて、とても単純な判断を行っています。第二層のパーセプトロンはなにをしているかというと、第一層のパーセプトロンの下した判断に重みを付けることで判断を下しています。第二層のパーセプトロンは、第一層のパーセプトロンよりも複雑で、抽象的な判断を下しているといえます。第三層のパーセプトロンはさらに複雑な判断を行っています。このように多層のニューラルネットワークは高度な意思決定を行うことができるます。  

パーセプトロンを定義した時、パーセプトロンは出力を1つしか持たないといいましたが、上図のネットワークの中のパーセプトロンは複数の出力を持つように書かれています。でも、あくまでもパーセプトロンの出力はひとつで、出力の矢印が複数あるのは、ただ、あるパーセプトロンの出力が複数のパーセプトロンの入力として使われていることを示しているに過ぎません。